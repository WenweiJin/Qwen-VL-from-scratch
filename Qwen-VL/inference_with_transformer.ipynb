{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型下载到local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.2+cu121 12.1\n",
      "Torch file: /usr/local/lib/python3.10/dist-packages/torch/__init__.py\n",
      "Has torch.vmap: True\n",
      "has functorch.apis.vmap: True\n",
      "Transformers version: 4.32.0\n",
      "Transformers file: /usr/local/lib/python3.10/dist-packages/transformers/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__, torch.version.cuda)\n",
    "print(\"Torch file:\", torch.__file__)\n",
    "\n",
    "# functorch/vmap 检查\n",
    "print(\"Has torch.vmap:\", hasattr(torch, \"vmap\"))\n",
    "try:\n",
    "    import torch._functorch.apis as apis\n",
    "    print(\"has functorch.apis.vmap:\", hasattr(apis, \"vmap\"))\n",
    "except Exception as e:\n",
    "    print(\"functorch.apis import error:\", e)\n",
    "\n",
    "import transformers\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Transformers file:\", transformers.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "CUDNN version: 8902\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"CUDNN version: {torch.backends.cudnn.version()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1618472228.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:46<00:00,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully from local path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#from modelscope import snapshot_download\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import sys\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# Downloading model checkpoint to a local dir model_dir\n",
    "# model_dir = snapshot_download('qwen/Qwen-VL')\n",
    "# model_dir = snapshot_download(repo_id='qwen/Qwen-VL-Chat')\n",
    "model_dir = \"models/Qwen-VL\"\n",
    "# 确保本地模型代码能被 import\n",
    "sys.path.append(model_dir)\n",
    "# 可选：显式指定 endpoint 避免联网\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "\n",
    "# Loading local checkpoints\n",
    "# trust_remote_code is still set as True since we still load codes from local dir instead of transformers\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map=\"cuda\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully from local path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torch\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Specify hyperparameters for generation\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_dir, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Picture 1: <img>N1_data/image_1.png</img>\n",
      "描述一下这个画面?\n",
      "tokenizer: QWenTokenizer(name_or_path='/mnt/ali-sh-1/usr/yujing1/workspaces/MLLM/Qwen-VL-from-scratch/Qwen-VL/models/Qwen-VL', vocab_size=151860, model_max_length=8192, is_fast=False, padding_side='right', truncation_side='right', special_tokens={}, clean_up_tokenization_spaces=True)\n",
      "这个画面中，有三个人，其中最显眼的是一个穿着黄色工作服、戴着VR眼镜的男子。这个男子的头发是棕色的，穿着黑色的裤子。画面的背景是一个房间，有两台电脑放在桌子上。\n"
     ]
    }
   ],
   "source": [
    "# 1st dialogue turn\n",
    "query = tokenizer.from_list_format([\n",
    "    {'image': 'N1_data/image_1.png'}, # Either a local path or an url\n",
    "    {'text': '描述一下这个画面?'},\n",
    "])\n",
    "print(\"query:\",query)\n",
    "print(\"tokenizer:\",tokenizer)\n",
    "response, history = model.chat(tokenizer, query=query, history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ref>戴眼镜的人人脸</ref><box>(339,175),(607,375)</box>\n"
     ]
    }
   ],
   "source": [
    "# 2nd dialogue turn\n",
    "response, history = model.chat(tokenizer, '框出图中戴眼镜的人的人脸', history=history)\n",
    "print(response)\n",
    "# <ref>击掌</ref><box>(536,509),(588,602)</box>\n",
    "image = tokenizer.draw_bbox_on_latest_picture(response, history)\n",
    "if image:\n",
    "  image.save('N1_data/image_1_box.jpg')\n",
    "else:\n",
    "  print(\"no box\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
